{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7043f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58eacf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"../half_season/h1_dfs/final_transition_out_of_poss_df_H1.csv\")\n",
    "final_df = final_df.rename(columns={'Unnamed: 0': 'uniqueTeamId'})\n",
    "team_ids_h1 = final_df['uniqueTeamId']\n",
    "final_df.set_index(\"uniqueTeamId\", inplace = True)\n",
    "final_df = final_df.fillna(0)\n",
    "\n",
    "final_df_h2 = pd.read_csv(\"../half_season/h2_dfs/final_transition_out_of_poss_df_H2.csv\")\n",
    "final_df_h2 = final_df.rename(columns={'Unnamed: 0': 'uniqueTeamId'}).reset_index()\n",
    "team_ids_h2 = final_df_h2['uniqueTeamId']\n",
    "final_df_h2 = final_df_h2.fillna(0)\n",
    "final_df_h2.set_index(\"uniqueTeamId\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ac836e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from kmedoids import KMedoids\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "from pyclustering.cluster import cluster_visualizer\n",
    "from pyclustering.utils import calculate_distance_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "    # Autoencoder for DEC\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=10):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "\n",
    "    # DEC model\n",
    "class DEC(nn.Module):\n",
    "    def __init__(self, encoder, cluster_centers):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.clusters = nn.Parameter(cluster_centers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        q = 1.0 / (1.0 + torch.sum((z.unsqueeze(1) - self.clusters)**2, dim=2))\n",
    "        q = q / torch.sum(q, dim=1, keepdim=True)\n",
    "        return q\n",
    "\n",
    "# Target distribution\n",
    "def target_distribution(q):\n",
    "    weight = q ** 2 / q.sum(0)\n",
    "    return (weight.t() / weight.sum(1)).t()\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def compute_indices(X, labels):\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    cluster_centers = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster_points = X[labels == i]\n",
    "        if len(cluster_points) == 0:\n",
    "            cluster_centers.append(np.zeros(X.shape[1]))\n",
    "        else:\n",
    "            cluster_centers.append(cluster_points.mean(axis=0))\n",
    "    cluster_centers = np.array(cluster_centers)\n",
    "\n",
    "    distances = pairwise_distances(X, cluster_centers)\n",
    "\n",
    "    # Iwcss: Sum of squared distances to cluster centers\n",
    "    Iwcss = sum(np.sum((X[labels == i] - cluster_centers[i]) ** 2) for i in range(n_clusters))\n",
    "\n",
    "    # Isep: Mean distance between all cluster centers\n",
    "    Isep = np.mean(cdist(cluster_centers, cluster_centers))\n",
    "\n",
    "    # Idistcc and Idens with filtering for valid clusters\n",
    "    valid_dists = []\n",
    "    valid_dens = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster_points = X[labels == i]\n",
    "        if len(cluster_points) < 2:\n",
    "            continue  # Skip small clusters to avoid NaN in mean/std\n",
    "        distances_to_center = np.linalg.norm(cluster_points - cluster_centers[i], axis=1)\n",
    "        valid_dists.append(np.mean(distances_to_center))\n",
    "        valid_dens.append(np.std(distances_to_center))\n",
    "\n",
    "    # Default to 0 if all clusters were invalid\n",
    "    Idistcc = np.mean(valid_dists) if valid_dists else 0.0\n",
    "    Idens = np.mean(valid_dens) if valid_dens else 0.0\n",
    "\n",
    "    return Iwcss, Isep, Idistcc, Idens\n",
    "\n",
    "\n",
    "\n",
    "def normalize(val, min_val, max_val, larger_is_better):\n",
    "    range_ = max_val - min_val\n",
    "    if np.isclose(range_, 0):\n",
    "        return 1.0  # or 0.5, depending on how you want to treat flat metrics\n",
    "    if larger_is_better:\n",
    "        return np.clip((val - min_val) / (range_ + 1e-10), 0, 1)\n",
    "    else:\n",
    "        return np.clip(1 - (val - min_val) / (range_ + 1e-10), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e45d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# If using GPU\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_h1 = scaler.fit_transform(final_df)          # FIT on H1\n",
    "X_h2 = scaler.transform(final_df_h2)           # TRANSFORM H2\n",
    "\n",
    "pca2 = PCA(n_components=2, random_state=42)\n",
    "X_h1_pca = pca2.fit_transform(X_h1)            # FIT on H1\n",
    "X_h2_pca = pca2.transform(X_h2)                # TRANSFORM H2\n",
    "\n",
    "X_h1_tensor = torch.tensor(X_h1, dtype=torch.float32)\n",
    "X_h2_tensor = torch.tensor(X_h2, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "dec_loss = {}\n",
    "\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "def predict_via_centroids(X_train, y_train, X_eval):\n",
    "    centers = np.vstack([X_train[y_train == c].mean(axis=0) for c in np.unique(y_train)])\n",
    "    return pairwise_distances_argmin(X_eval, centers)  # nearest center id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a25e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "results = []\n",
    "\n",
    "for k in range(2, 11):\n",
    "    clusterings = {\n",
    "        \"kmeans\": KMeans(n_clusters=k, random_state=42),\n",
    "        \"kmedoids\": KMedoids(n_clusters=k, metric=\"euclidean\", init=\"random\", max_iter=300, random_state=42),\n",
    "        \"ward\": AgglomerativeClustering(n_clusters=k, linkage=\"ward\"),\n",
    "    }\n",
    "\n",
    "    # ====== RAW space (scaled) ======\n",
    "    for method_name, model in clusterings.items():\n",
    "        # fit on H1\n",
    "        y_h1 = model.fit_predict(X_h1)\n",
    "\n",
    "        # get H2 labels\n",
    "        if hasattr(model, \"predict\"):\n",
    "            y_h2 = model.predict(X_h2)\n",
    "        else:\n",
    "            y_h2 = predict_via_centroids(X_h1, y_h1, X_h2)  # Ward\n",
    "\n",
    "        # evaluate on H2\n",
    "        sil = silhouette_score(X_h2, y_h2)\n",
    "        Iwcss, Isep, Idistcc, Idens = compute_indices(X_h2, y_h2)\n",
    "\n",
    "        results.append({\n",
    "            \"k\": k,\n",
    "            \"method\": method_name,\n",
    "            \"silhouette_score\": sil,\n",
    "            \"Iwcss\": Iwcss,\n",
    "            \"Isep\": Isep,\n",
    "            \"Idistcc\": Idistcc,\n",
    "            \"Idens\": Idens\n",
    "        })\n",
    "\n",
    "    # ====== PCA space ======\n",
    "    for method_name, model in clusterings.items():\n",
    "        y_h1 = model.fit_predict(X_h1_pca)\n",
    "\n",
    "        if hasattr(model, \"predict\"):\n",
    "            y_h2 = model.predict(X_h2_pca)\n",
    "        else:\n",
    "            y_h2 = predict_via_centroids(X_h1_pca, y_h1, X_h2_pca)\n",
    "\n",
    "        sil = silhouette_score(X_h2_pca, y_h2)\n",
    "        Iwcss, Isep, Idistcc, Idens = compute_indices(X_h2_pca, y_h2)\n",
    "\n",
    "        results.append({\n",
    "            \"k\": k,\n",
    "            \"method\": f\"{method_name}_pca\",\n",
    "            \"silhouette_score\": sil,\n",
    "            \"Iwcss\": Iwcss,\n",
    "            \"Isep\": Isep,\n",
    "            \"Idistcc\": Idistcc,\n",
    "            \"Idens\": Idens\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b5e6c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "k == 2\n",
      "AE training...\n",
      "Epoch: 0\n",
      "Epoch: 500\n",
      "Epoch: 1000\n",
      "Epoch: 1500\n",
      "Epoch: 2000\n",
      "Epoch: 2500\n",
      "DEC training...\n",
      "Epoch: 0\n",
      "Epoch: 500\n",
      "Epoch: 1000\n",
      "Epoch: 1500\n",
      "Epoch: 2000\n",
      "Epoch: 2500\n",
      "------------------------------\n",
      "k == 3\n",
      "AE training...\n",
      "Epoch: 0\n",
      "Epoch: 500\n",
      "Epoch: 1000\n",
      "Epoch: 1500\n",
      "Epoch: 2000\n",
      "Epoch: 2500\n",
      "DEC training...\n",
      "Epoch: 0\n",
      "Epoch: 500\n",
      "Epoch: 1000\n",
      "Epoch: 1500\n",
      "Epoch: 2000\n",
      "Epoch: 2500\n",
      "------------------------------\n",
      "k == 4\n",
      "AE training...\n",
      "Epoch: 0\n",
      "Epoch: 500\n",
      "Epoch: 1000\n",
      "Epoch: 1500\n",
      "Epoch: 2000\n",
      "Epoch: 2500\n",
      "DEC training...\n",
      "Epoch: 0\n",
      "Epoch: 500\n",
      "Epoch: 1000\n",
      "Epoch: 1500\n",
      "Epoch: 2000\n",
      "Epoch: 2500\n",
      "------------------------------\n",
      "k == 5\n",
      "AE training...\n",
      "Epoch: 0\n",
      "Epoch: 500\n",
      "Epoch: 1000\n",
      "Epoch: 1500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ed45b4078dd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_h1_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_h1_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m500\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eged1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m             )\n\u001b[1;32m--> 525\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\eged1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     _engine_run_backward(\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eged1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\autograd\\graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in range(2, 11):\n",
    "    print(\"---\"*10)\n",
    "    print(f\"k == {k}\")\n",
    "    input_dim = X_h1.shape[1]\n",
    "    latent_dim = 10\n",
    "\n",
    "    ae = AutoEncoder(input_dim, latent_dim)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(ae.parameters(), lr=1e-3)\n",
    "\n",
    "    print(\"AE training...\")\n",
    "    # AE pretrain on H1\n",
    "    for epoch in range(3000):\n",
    "        optimizer.zero_grad()\n",
    "        out = ae(X_h1_tensor)\n",
    "        loss = criterion(out, X_h1_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        if epoch % 500 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "\n",
    "    # init clusters using H1 latent\n",
    "    z_h1 = ae.encoder(X_h1_tensor).detach().numpy()\n",
    "    km = KMeans(n_clusters=k, random_state=42).fit(z_h1)\n",
    "    init_centers = torch.tensor(km.cluster_centers_, dtype=torch.float32)\n",
    "\n",
    "    dec = DEC(ae.encoder, init_centers.clone())\n",
    "    dec_opt = optim.Adam(dec.parameters(), lr=1e-3)\n",
    "\n",
    "    print(\"DEC training...\")\n",
    "    # DEC train on H1\n",
    "    for epoch in range(3000): \n",
    "        q = dec(X_h1_tensor)\n",
    "        p = target_distribution(q.detach())\n",
    "        kl = torch.nn.functional.kl_div(q.log(), p, reduction=\"batchmean\")\n",
    "        dec_opt.zero_grad()\n",
    "        kl.backward()\n",
    "        dec_opt.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "\n",
    "    # ===== evaluate on H2 =====\n",
    "    with torch.no_grad():\n",
    "        z_h2 = dec.encoder(X_h2_tensor).cpu().numpy()\n",
    "        q_h2 = dec(X_h2_tensor)\n",
    "        y_h2 = torch.argmax(q_h2, dim=1).cpu().numpy()\n",
    "\n",
    "    sil = silhouette_score(z_h2, y_h2)\n",
    "    Iwcss, Isep, Idistcc, Idens = compute_indices(z_h2, y_h2)\n",
    "\n",
    "    results.append({\n",
    "        \"k\": k,\n",
    "        \"method\": \"dec\",\n",
    "        \"silhouette_score\": sil,\n",
    "        \"Iwcss\": Iwcss,\n",
    "        \"Isep\": Isep,\n",
    "        \"Idistcc\": Idistcc,\n",
    "        \"Idens\": Idens\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19769c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalization function\n",
    "def minmax_normalize(val, min_val, max_val, larger_is_better):\n",
    "    if np.isclose(max_val - min_val, 0):\n",
    "        return 1.0\n",
    "    score = (val - min_val) / (max_val - min_val)\n",
    "    return score if larger_is_better else 1 - score\n",
    "\n",
    "results_normalized = []\n",
    "\n",
    "# Compute global min and max values for each metric\n",
    "index_min = {\n",
    "    'Iwcss': min(row['Iwcss'] for row in results),\n",
    "    'Isep': min(row['Isep'] for row in results),\n",
    "    'Idistcc': min(row['Idistcc'] for row in results),\n",
    "    'Idens': min(row['Idens'] for row in results),\n",
    "}\n",
    "\n",
    "index_max = {\n",
    "    'Iwcss': max(row['Iwcss'] for row in results),\n",
    "    'Isep': max(row['Isep'] for row in results),\n",
    "    'Idistcc': max(row['Idistcc'] for row in results),\n",
    "    'Idens': max(row['Idens'] for row in results),\n",
    "}\n",
    "\n",
    "for row in results:\n",
    "    # Min-max normalization\n",
    "    Iwcss_m = minmax_normalize(row['Iwcss'], index_min['Iwcss'], index_max['Iwcss'], larger_is_better=False)\n",
    "    Isep_m = minmax_normalize(row['Isep'], index_min['Isep'], index_max['Isep'], larger_is_better=True)\n",
    "    Idistcc_m = minmax_normalize(row['Idistcc'], index_min['Idistcc'], index_max['Idistcc'], larger_is_better=False)\n",
    "    Idens_m = minmax_normalize(row['Idens'], index_min['Idens'], index_max['Idens'], larger_is_better=False)\n",
    "\n",
    "    AC1_m = (Iwcss_m + Isep_m + Idistcc_m + Idens_m) / 4\n",
    "    AC2_m = (1 * Iwcss_m + 0.5 * Isep_m + 1 * Idistcc_m + 0.25 * Idens_m) / 2.75\n",
    "\n",
    "    results_normalized.append({\n",
    "        'k': row['k'],\n",
    "        'method': row['method'],\n",
    "        'silhouette_score': row['silhouette_score'],\n",
    "        #'AC1_zscore': AC1_z,\n",
    "        #'AC2_zscore': AC2_z,\n",
    "        'AC1': AC1_m,\n",
    "        'AC2': AC2_m\n",
    "    })\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "results_zscore_df = pd.DataFrame(results_normalized)\n",
    "results_zscore_df.sort_values(by=['AC2'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results_zscore_df.copy()\n",
    "\n",
    "# Define mapping\n",
    "old_methods = ['dec', 'kmeans', 'kmeans_pca', 'kmedoids', 'kmedoids_pca', 'ward', 'ward_pca']\n",
    "new_methods = ['DEC (proposed method)', 'K-Means', 'K-Means_with_pca', 'K-Medoids', 'K-Medoids_with_pca', 'Ward', 'Ward_with_pca']\n",
    "method_map = dict(zip(old_methods, new_methods))\n",
    "\n",
    "# Apply mapping\n",
    "df['method'] = df['method'].map(method_map)\n",
    "\n",
    "\n",
    "# Ensure columns are correct and values are flattened\n",
    "df['k'] = df['k'].astype(int)\n",
    "df['silhouette_score'] = df['silhouette_score'].astype(float)\n",
    "df['AC1'] = df['AC1'].astype(float)\n",
    "df['AC2'] = df['AC2'].astype(float)\n",
    "\n",
    "# Define method groups and colors\n",
    "methods = ['DEC (proposed method)', 'K-Means', 'K-Means_with_pca', 'K-Medoids', 'K-Medoids_with_pca', 'Ward', 'Ward_with_pca']\n",
    "base_colors = {\n",
    "    'K-Means': '#1f77b4',\n",
    "    'K-Medoids': '#ff7f0e',\n",
    "    'Ward': '#2ca02c'\n",
    "}\n",
    "highlight_color = '#d62728'  # red for 'DEC (proposed method)'\n",
    "\n",
    "# Color map with pale variants for base methods and shared colors\n",
    "color_map = {\n",
    "    'DEC (proposed method)': highlight_color,\n",
    "    'K-Means': base_colors['K-Means'] + '80',\n",
    "    'K-Means_with_pca': base_colors['K-Means'],\n",
    "    'K-Medoids': base_colors['K-Medoids'] + '80',\n",
    "    'K-Medoids_with_pca': base_colors['K-Medoids'],\n",
    "    'Ward': base_colors['Ward'] + '80',\n",
    "    'Ward_with_pca': base_colors['Ward']\n",
    "}\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 15), sharex=True)\n",
    "metrics = ['silhouette_score', 'AC1', 'AC2']\n",
    "ylabels = ['Silhouette Score', 'A(C)1', 'A(C)2']\n",
    "\n",
    "for ax, metric, ylabel in zip(axs, metrics, ylabels):\n",
    "    for method in methods:\n",
    "        subset = df[df['method'] == method]\n",
    "        x = subset['k'].to_numpy()\n",
    "        y = subset[metric].to_numpy()\n",
    "        ax.plot(x, y, label=method,\n",
    "                color=color_map[method], linewidth=2 if method == 'DEC (proposed method)' else 1.5)\n",
    "        ax.scatter(x, y, color=color_map[method], s=40)\n",
    "        if method == 'DEC (proposed method)':\n",
    "            ax.text(x[-1] + 0.1, y[-1], 'DEC', color=color_map[method],\n",
    "                    fontsize=12, fontweight='bold', va='center')\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    ax.grid(True)\n",
    "\n",
    "axs[-1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "fig.suptitle(\"Evaluation of Clustering on 'Transition-Out-of-Possesion' Data\", fontsize=16, fontweight='bold', y=.95)\n",
    "axs[0].legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=4, fontsize=10, frameon=False)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
